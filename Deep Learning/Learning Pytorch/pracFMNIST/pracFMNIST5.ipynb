{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pracFMNIST5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfLCv2-gDg5C",
        "colab_type": "text"
      },
      "source": [
        "using num_workers attribute of the data_loader class to increase training speed.<br>\n",
        "(improvising on pracFMNIST4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvZFJbHaiZqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from IPython.display import display, clear_output\n",
        "import pandas as pd\n",
        "import time\n",
        "import json\n",
        "\n",
        "from itertools import product\n",
        "from collections import namedtuple\n",
        "from collections import OrderedDict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT6tGRLBihT1",
        "colab_type": "code",
        "outputId": "9d15e63f-f18e-4d92-8136-5425c4b24049",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "use_cuda = True\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBF6gBO1ivza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RunBuilder():\n",
        "    @staticmethod\n",
        "    def get_runs(params):\n",
        "        Run = namedtuple('Run',params.keys())\n",
        "        runs = []\n",
        "        for  v in product(*params.values()):\n",
        "            runs.append(Run(*v))\n",
        "        return runs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRgQ5OUgjuMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RunManager():\n",
        "    def __init__(self):\n",
        "\n",
        "        self.epoch_count = 0\n",
        "        self.epoch_loss = 0\n",
        "        self.epoch_num_correct = 0\n",
        "        self.epoch_start_time = None\n",
        "\n",
        "        self.run_params = None\n",
        "        self.run_count = 0\n",
        "        self.run_data = []\n",
        "        self.run_start_time = None\n",
        "\n",
        "        self.network = None\n",
        "        self.loader = None\n",
        "        self.tb = None\n",
        "\n",
        "    def begin_run(self,run,network,loader):\n",
        "        \n",
        "        self.run_start_time = time.time()\n",
        "        \n",
        "        self.run_params = run \n",
        "        self.run_count += 1\n",
        "        \n",
        "        self.network = network\n",
        "        self.loader = loader\n",
        "        self.tb = SummaryWriter(comment=f'-{run}')\n",
        "\n",
        "        images,labels = next(iter(self.loader))\n",
        "\n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "            images = images.cuda()\n",
        "        \n",
        "        grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "        self.tb.add_image('images',grid)\n",
        "        self.tb.add_graph(self.network,images)\n",
        "\n",
        "    def end_run(self):\n",
        "        self.tb.close()\n",
        "        self.epoch_count = 0\n",
        "\n",
        "    def begin_epoch(self):\n",
        "        \n",
        "        self.epoch_start_time = time.time()\n",
        "        \n",
        "        self.epoch_count += 1\n",
        "        self.epoch_loss = 0\n",
        "        self.epoch_num_correct = 0\n",
        "\n",
        "    def end_epoch(self):\n",
        "\n",
        "        epoch_duration = time.time() - self.epoch_start_time\n",
        "        run_duration = time.time() - self.run_start_time\n",
        "\n",
        "        loss = self.epoch_loss / len(self.loader.dataset)\n",
        "        accuracy = self.epoch_num_correct / len(self.loader.dataset)\n",
        "\n",
        "        self.tb.add_scalar('Loss',loss,self.epoch_count)\n",
        "        self.tb.add_scalar('Accuracy',accuracy,self.epoch_count)\n",
        "\n",
        "        for name,param in self.network.named_parameters():\n",
        "            self.tb.add_histogram(name,param,self.epoch_count)\n",
        "            self.tb.add_histogram(f'{name}.grad',param.grad,self.epoch_count)\n",
        "\n",
        "        results = OrderedDict()\n",
        "        results[\"run\"] = self.run_count\n",
        "        results[\"epoch\"] = self.epoch_count\n",
        "        results[\"loss\"] = loss\n",
        "        results[\"accuracy\"] = accuracy\n",
        "        results[\"epoch duration\"] = epoch_duration\n",
        "        results[\"run duration\"] = run_duration\n",
        "\n",
        "        for k,v in self.run_params._asdict().items(): results[k] = v\n",
        "        self.run_data.append(results)\n",
        "\n",
        "        df = pd.DataFrame.from_dict(self.run_data,orient='columns')\n",
        "\n",
        "        clear_output(wait=True)     #specific to ipynbs\n",
        "        display(df)                 #specific to ipynbs\n",
        "\n",
        "    def track_loss(self,loss):\n",
        "        self.epoch_loss += loss.item()*self.loader.batch_size\n",
        "\n",
        "    def track_num_correct(self,preds,labels):\n",
        "        self.epoch_num_correct += self._get_num_correct(preds,labels)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _get_num_correct(self,pred,labels):\n",
        "        return preds.argmax(dim=1).eq(labels).sum().item()\n",
        "\n",
        "    def save(self,fileName):\n",
        "\n",
        "        pd.DataFrame.from_dict(\n",
        "            self.run_data,\n",
        "            orient=\"columns\",\n",
        "        ).to_csv(f'{fileName}.csv')\n",
        "\n",
        "        with open(f'{fileName}.json','w',encoding = 'utf-8') as f:\n",
        "            json.dump(self.run_data,f,ensure_ascii = False,indent=4)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s09guQ4AL97I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1,6,5)\n",
        "        self.conv2 = nn.Conv2d(6,12,5)\n",
        "\n",
        "        self.fc1 = nn.Linear(12*4*4,120)\n",
        "        self.fc2 = nn.Linear(120,60)\n",
        "        self.out = nn.Linear(60,10)\n",
        "\n",
        "    def forward(self,t):\n",
        "        t = F.relu(self.conv1(t))\n",
        "        t = F.max_pool2d(t,kernel_size=2,stride=2)\n",
        "        \n",
        "        t = F.relu(self.conv2(t))\n",
        "        t = F.max_pool2d(t,kernel_size=2,stride=2)\n",
        "\n",
        "        t = t.flatten(start_dim=1)\n",
        "        t = F.relu(self.fc1(t))\n",
        "\n",
        "        t = F.relu(self.fc2(t))\n",
        "\n",
        "        t = self.out(t)\n",
        "\n",
        "        return t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2Id9Ma2MCvU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "c679574a-425d-4b88-a70c-ef6e207b8534"
      },
      "source": [
        "train_set = torchvision.datasets.FashionMNIST(\n",
        "    root = \"./data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms.Compose(\n",
        "        [transforms.ToTensor()]\n",
        "    )\n",
        ")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set,batch_size=100,shuffle=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "26427392it [00:02, 9607628.44it/s]                              \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 75342.87it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4423680it [00:01, 3097575.73it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 26960.57it/s]            "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asFr83z7rmRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = OrderedDict(\n",
        "    lr = [0.01],\n",
        "    batch_size = [100,1000,10000],\n",
        "    num_workers = [0,1,2,4,8,16]\n",
        ")\n",
        "\n",
        "class RunManager():\n",
        "    def __init__(self):\n",
        "\n",
        "        self.epoch_count = 0\n",
        "        self.epoch_loss = 0\n",
        "        self.epoch_num_correct = 0\n",
        "        self.epoch_start_time = None\n",
        "\n",
        "        self.run_params = None\n",
        "        self.run_count = 0\n",
        "        self.run_data = []\n",
        "        self.run_start_time = None\n",
        "\n",
        "        self.network = None\n",
        "        self.loader = None\n",
        "        self.tb = None\n",
        "\n",
        "    def begin_run(self,run,network,loader):\n",
        "        \n",
        "        self.run_start_time = time.time()\n",
        "        \n",
        "        self.run_params = run \n",
        "        self.run_count += 1\n",
        "        \n",
        "        self.network = network\n",
        "        self.loader = loader\n",
        "        self.tb = SummaryWriter(comment=f'-{run}')\n",
        "\n",
        "        images,labels = next(iter(self.loader))\n",
        "\n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "            images = images.cuda()\n",
        "        \n",
        "        grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "        self.tb.add_image('images',grid)\n",
        "        self.tb.add_graph(self.network,images)\n",
        "\n",
        "    def end_run(self):\n",
        "        self.tb.close()\n",
        "        self.epoch_count = 0\n",
        "\n",
        "    def begin_epoch(self):\n",
        "        \n",
        "        self.epoch_start_time = time.time()\n",
        "        \n",
        "        self.epoch_count += 1\n",
        "        self.epoch_loss = 0\n",
        "        self.epoch_num_correct = 0\n",
        "\n",
        "    def end_epoch(self):\n",
        "\n",
        "        epoch_duration = time.time() - self.epoch_start_time\n",
        "        run_duration = time.time() - self.run_start_time\n",
        "\n",
        "        loss = self.epoch_loss / len(self.loader.dataset)\n",
        "        accuracy = self.epoch_num_correct / len(self.loader.dataset)\n",
        "\n",
        "        self.tb.add_scalar('Loss',loss,self.epoch_count)\n",
        "        self.tb.add_scalar('Accuracy',accuracy,self.epoch_count)\n",
        "\n",
        "        for name,param in self.network.named_parameters():\n",
        "            self.tb.add_histogram(name,param,self.epoch_count)\n",
        "            self.tb.add_histogram(f'{name}.grad',param.grad,self.epoch_count)\n",
        "\n",
        "        results = OrderedDict()\n",
        "        results[\"run\"] = self.run_count\n",
        "        results[\"epoch\"] = self.epoch_count\n",
        "        results[\"loss\"] = loss\n",
        "        results[\"accuracy\"] = accuracy\n",
        "        results[\"epoch duration\"] = epoch_duration\n",
        "        results[\"run duration\"] = run_duration\n",
        "\n",
        "        for k,v in self.run_params._asdict().items(): results[k] = v\n",
        "        self.run_data.append(results)\n",
        "\n",
        "        df = pd.DataFrame.from_dict(self.run_data,orient='columns')\n",
        "\n",
        "        clear_output(wait=True)     #specific to ipynbs\n",
        "        display(df)                 #specific to ipynbs\n",
        "\n",
        "    def track_loss(self,loss):\n",
        "        self.epoch_loss += loss.item()*self.loader.batch_size\n",
        "\n",
        "    def track_num_correct(self,preds,labels):\n",
        "        self.epoch_num_correct += self._get_num_correct(preds,labels)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _get_num_correct(self,pred,labels):\n",
        "        return preds.argmax(dim=1).eq(labels).sum().item()\n",
        "\n",
        "    def save(self,fileName):\n",
        "\n",
        "        pd.DataFrame.from_dict(\n",
        "            self.run_data,\n",
        "            orient=\"columns\",\n",
        "        ).to_csv(f'{fileName}.csv')\n",
        "\n",
        "        with open(f'{fileName}.json','w',encoding = 'utf-8') as f:\n",
        "            json.dump(self.run_data,f,ensure_ascii = False,indent=4)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pSvxb1Nxp4p",
        "colab_type": "code",
        "outputId": "43730b59-1c1b-4e80-e890-97c3a151c4ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "!rm -r runs"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'runs': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyXu3g1mi-IS",
        "colab_type": "code",
        "outputId": "a8f13b13-6937-481f-b01a-6d78cd26c534",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        }
      },
      "source": [
        "m = RunManager()\n",
        "for run in RunBuilder.get_runs(params):\n",
        "    \n",
        "    network = Network()     \n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "        network.cuda()\n",
        "\n",
        "    loader = DataLoader(train_set,batch_size = run.batch_size,num_workers = run.num_workers)\n",
        "    optimizer = optim.Adam(network.parameters(),lr=run.lr)\n",
        "\n",
        "    m.begin_run(run,network,loader)\n",
        "    for epoch in range(1):\n",
        "        m.begin_epoch()\n",
        "        for batch in loader:\n",
        "\n",
        "            images = batch[0].cuda()\n",
        "            labels = batch[1].cuda()\n",
        "\n",
        "            preds = network(images)\n",
        "            loss = F.cross_entropy(preds,labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            m.track_loss(loss)\n",
        "            m.track_num_correct(preds,labels)\n",
        "\n",
        "        m.end_epoch()\n",
        "    m.end_run()\n",
        "m.save('results')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>run</th>\n",
              "      <th>epoch</th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>epoch duration</th>\n",
              "      <th>run duration</th>\n",
              "      <th>lr</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>num_workers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.579461</td>\n",
              "      <td>0.780567</td>\n",
              "      <td>9.546074</td>\n",
              "      <td>11.560656</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.552522</td>\n",
              "      <td>0.788583</td>\n",
              "      <td>10.557312</td>\n",
              "      <td>10.738400</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.537637</td>\n",
              "      <td>0.794117</td>\n",
              "      <td>9.256456</td>\n",
              "      <td>9.467849</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.544890</td>\n",
              "      <td>0.792850</td>\n",
              "      <td>9.140315</td>\n",
              "      <td>9.470607</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.575684</td>\n",
              "      <td>0.778983</td>\n",
              "      <td>9.372262</td>\n",
              "      <td>9.942099</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0.550750</td>\n",
              "      <td>0.792567</td>\n",
              "      <td>9.786679</td>\n",
              "      <td>10.822042</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1.011354</td>\n",
              "      <td>0.607850</td>\n",
              "      <td>8.181900</td>\n",
              "      <td>8.819124</td>\n",
              "      <td>0.01</td>\n",
              "      <td>1000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1.002562</td>\n",
              "      <td>0.621433</td>\n",
              "      <td>7.624650</td>\n",
              "      <td>8.454855</td>\n",
              "      <td>0.01</td>\n",
              "      <td>1000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>1.095863</td>\n",
              "      <td>0.580900</td>\n",
              "      <td>6.105537</td>\n",
              "      <td>7.062789</td>\n",
              "      <td>0.01</td>\n",
              "      <td>1000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>0.959910</td>\n",
              "      <td>0.631033</td>\n",
              "      <td>6.201076</td>\n",
              "      <td>7.575699</td>\n",
              "      <td>0.01</td>\n",
              "      <td>1000</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0.908971</td>\n",
              "      <td>0.649350</td>\n",
              "      <td>6.321060</td>\n",
              "      <td>8.569769</td>\n",
              "      <td>0.01</td>\n",
              "      <td>1000</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>0.989000</td>\n",
              "      <td>0.622533</td>\n",
              "      <td>6.743102</td>\n",
              "      <td>9.974137</td>\n",
              "      <td>0.01</td>\n",
              "      <td>1000</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>2.076882</td>\n",
              "      <td>0.216083</td>\n",
              "      <td>9.089075</td>\n",
              "      <td>13.706095</td>\n",
              "      <td>0.01</td>\n",
              "      <td>10000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>2.171865</td>\n",
              "      <td>0.190483</td>\n",
              "      <td>8.363791</td>\n",
              "      <td>14.241621</td>\n",
              "      <td>0.01</td>\n",
              "      <td>10000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>2.152270</td>\n",
              "      <td>0.181717</td>\n",
              "      <td>7.490500</td>\n",
              "      <td>14.613247</td>\n",
              "      <td>0.01</td>\n",
              "      <td>10000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>2.207171</td>\n",
              "      <td>0.157167</td>\n",
              "      <td>7.623116</td>\n",
              "      <td>16.143849</td>\n",
              "      <td>0.01</td>\n",
              "      <td>10000</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>2.052194</td>\n",
              "      <td>0.273433</td>\n",
              "      <td>7.696203</td>\n",
              "      <td>17.363528</td>\n",
              "      <td>0.01</td>\n",
              "      <td>10000</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>2.139387</td>\n",
              "      <td>0.237900</td>\n",
              "      <td>8.609009</td>\n",
              "      <td>17.909838</td>\n",
              "      <td>0.01</td>\n",
              "      <td>10000</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    run  epoch      loss  accuracy  ...  run duration    lr  batch_size  num_workers\n",
              "0     1      1  0.579461  0.780567  ...     11.560656  0.01         100            0\n",
              "1     2      1  0.552522  0.788583  ...     10.738400  0.01         100            1\n",
              "2     3      1  0.537637  0.794117  ...      9.467849  0.01         100            2\n",
              "3     4      1  0.544890  0.792850  ...      9.470607  0.01         100            4\n",
              "4     5      1  0.575684  0.778983  ...      9.942099  0.01         100            8\n",
              "5     6      1  0.550750  0.792567  ...     10.822042  0.01         100           16\n",
              "6     7      1  1.011354  0.607850  ...      8.819124  0.01        1000            0\n",
              "7     8      1  1.002562  0.621433  ...      8.454855  0.01        1000            1\n",
              "8     9      1  1.095863  0.580900  ...      7.062789  0.01        1000            2\n",
              "9    10      1  0.959910  0.631033  ...      7.575699  0.01        1000            4\n",
              "10   11      1  0.908971  0.649350  ...      8.569769  0.01        1000            8\n",
              "11   12      1  0.989000  0.622533  ...      9.974137  0.01        1000           16\n",
              "12   13      1  2.076882  0.216083  ...     13.706095  0.01       10000            0\n",
              "13   14      1  2.171865  0.190483  ...     14.241621  0.01       10000            1\n",
              "14   15      1  2.152270  0.181717  ...     14.613247  0.01       10000            2\n",
              "15   16      1  2.207171  0.157167  ...     16.143849  0.01       10000            4\n",
              "16   17      1  2.052194  0.273433  ...     17.363528  0.01       10000            8\n",
              "17   18      1  2.139387  0.237900  ...     17.909838  0.01       10000           16\n",
              "\n",
              "[18 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUBY1YYRzfHO",
        "colab_type": "text"
      },
      "source": [
        "downloading runs for visualising on tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EORKTK7TzjUo",
        "colab_type": "code",
        "outputId": "500ee6ae-fd50-45ad-fd90-e0f396dd7097",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "!zip -r runs3 runs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: runs/ (stored 0%)\n",
            "  adding: runs/Oct29_13-50-59_0eca79d7de00-Run(lr=0.01, batch_size=1000, shuffle=True)/ (stored 0%)\n",
            "  adding: runs/Oct29_13-50-59_0eca79d7de00-Run(lr=0.01, batch_size=1000, shuffle=True)/events.out.tfevents.1572357059.0eca79d7de00.122.6 (deflated 51%)\n",
            "  adding: runs/Oct29_13-53-07_0eca79d7de00-Run(lr=0.01, batch_size=2000, shuffle=False)/ (stored 0%)\n",
            "  adding: runs/Oct29_13-53-07_0eca79d7de00-Run(lr=0.01, batch_size=2000, shuffle=False)/events.out.tfevents.1572357187.0eca79d7de00.122.9 (deflated 35%)\n",
            "  adding: runs/Oct29_13-51-41_0eca79d7de00-Run(lr=0.01, batch_size=1000, shuffle=False)/ (stored 0%)\n",
            "  adding: runs/Oct29_13-51-41_0eca79d7de00-Run(lr=0.01, batch_size=1000, shuffle=False)/events.out.tfevents.1572357101.0eca79d7de00.122.7 (deflated 51%)\n",
            "  adding: runs/Oct29_13-52-24_0eca79d7de00-Run(lr=0.01, batch_size=2000, shuffle=True)/ (stored 0%)\n",
            "  adding: runs/Oct29_13-52-24_0eca79d7de00-Run(lr=0.01, batch_size=2000, shuffle=True)/events.out.tfevents.1572357144.0eca79d7de00.122.8 (deflated 35%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhxMyx6FzzbZ",
        "colab_type": "text"
      },
      "source": [
        "optimal num_workers = 1 , further increase doesn't help much"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLnYQkisGBQo",
        "colab_type": "text"
      },
      "source": [
        "num_workers  indicates how many subprocesses to use for data loading.<br>\n",
        "will be using a hard coded 1 from the next time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FG3FtKl6Gbbs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757
        },
        "outputId": "14c8bdbb-df68-47cd-a1b5-1343e8bac20f"
      },
      "source": [
        "!zip -r runs4 runs"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: runs/ (stored 0%)\n",
            "  adding: runs/Oct29_15-13-45_4762073abd70-Run(lr=0.01, batch_size=1000, num_workers=1)/ (stored 0%)\n",
            "  adding: runs/Oct29_15-13-45_4762073abd70-Run(lr=0.01, batch_size=1000, num_workers=1)/events.out.tfevents.1572362025.4762073abd70.122.7 (deflated 20%)\n",
            "  adding: runs/Oct29_15-14-28_4762073abd70-Run(lr=0.01, batch_size=10000, num_workers=0)/ (stored 0%)\n",
            "  adding: runs/Oct29_15-14-28_4762073abd70-Run(lr=0.01, batch_size=10000, num_workers=0)/events.out.tfevents.1572362068.4762073abd70.122.12 (deflated 6%)\n",
            "  adding: runs/Oct29_15-13-15_4762073abd70-Run(lr=0.01, batch_size=100, num_workers=8)/ (stored 0%)\n",
            "  adding: runs/Oct29_15-13-15_4762073abd70-Run(lr=0.01, batch_size=100, num_workers=8)/events.out.tfevents.1572361995.4762073abd70.122.4 (deflated 65%)\n",
            "  adding: runs/Oct29_15-14-09_4762073abd70-Run(lr=0.01, batch_size=1000, num_workers=8)/ (stored 0%)\n",
            "  adding: runs/Oct29_15-14-09_4762073abd70-Run(lr=0.01, batch_size=1000, num_workers=8)/events.out.tfevents.1572362049.4762073abd70.122.10 (deflated 20%)\n",
            "  adding: runs/Oct29_15-12-34_4762073abd70-Run(lr=0.01, batch_size=100, num_workers=0)/ (stored 0%)\n",
            "  adding: runs/Oct29_15-12-34_4762073abd70-Run(lr=0.01, batch_size=100, num_workers=0)/events.out.tfevents.1572361955.4762073abd70.122.0 (deflated 65%)\n",
            "  adding: runs/Oct29_15-13-25_4762073abd70-Run(lr=0.01, batch_size=100, num_workers=16)/ (stored 0%)\n",
            "  adding: runs/Oct29_15-13-25_4762073abd70-Run(lr=0.01, batch_size=100, num_workers=16)/events.out.tfevents.1572362005.4762073abd70.122.5 (deflated 65%)\n",
            "  adding: runs/Oct29_15-14-42_4762073abd70-Run(lr=0.01, batch_size=10000, num_workers=1)/ (stored 0%)\n",
            "  adding: runs/Oct29_15-14-42_4762073abd70-Run(lr=0.01, batch_size=10000, num_workers=1)/events.out.tfevents.1572362082.4762073abd70.122.13 (deflated 6%)\n",
            "  adding: runs/Oct29_15-14-01_4762073abd70-Run(lr=0.01, batch_size=1000, num_workers=4)/ (stored 0%)\n",
            "  adding: runs/Oct29_15-14-01_4762073abd70-Run(lr=0.01, batch_size=1000, num_workers=4)/events.out.tfevents.1572362041.4762073abd70.122.9 (deflated 20%)\n",
            "  adding: runs/Oct29_15-12-45_4762073abd70-Run(lr=0.01, batch_size=100, num_workers=1)/ (stored 0%)\n",
            "  adding: runs/Oct29_15-12-45_4762073abd70-Run(lr=0.01, batch_size=100, num_workers=1)/events.out.tfevents.1572361965.4762073abd70.122.1 (deflated 65%)\n",
            "  adding: runs/Oct29_15-15-45_4762073abd70-Run(lr=0.01, batch_size=10000, num_workers=16)/ (stored 0%)\n",
            "  adding: runs/Oct29_15-15-45_4762073abd70-Run(lr=0.01, batch_size=10000, num_workers=16)/events.out.tfevents.1572362145.4762073abd70.122.17 (deflated 6%)\n",
            "  adding: runs/Oct29_15-12-56_4762073abd70-Run(lr=0.01, batch_size=100, num_workers=2)/ (stored 0%)\n",
            "  adding: runs/Oct29_15-12-56_4762073abd70-Run(lr=0.01, batch_size=100, num_workers=2)/events.out.tfevents.1572361976.4762073abd70.122.2 (deflated 65%)\n",
            "  adding: runs/Oct29_15-13-06_4762073abd70-Run(lr=0.01, batch_size=100, num_workers=4)/ (stored 0%)\n",
            "  adding: runs/Oct29_15-13-06_4762073abd70-Run(lr=0.01, batch_size=100, num_workers=4)/events.out.tfevents.1572361986.4762073abd70.122.3 (deflated 65%)\n",
            "  adding: runs/Oct29_15-15-11_4762073abd70-Run(lr=0.01, batch_size=10000, num_workers=4)/ (stored 0%)\n",
            "  adding: runs/Oct29_15-15-11_4762073abd70-Run(lr=0.01, batch_size=10000, num_workers=4)/events.out.tfevents.1572362111.4762073abd70.122.15 (deflated 6%)\n",
            "  adding: runs/Oct29_15-15-27_4762073abd70-Run(lr=0.01, batch_size=10000, num_workers=8)/ (stored 0%)\n",
            "  adding: runs/Oct29_15-15-27_4762073abd70-Run(lr=0.01, batch_size=10000, num_workers=8)/events.out.tfevents.1572362127.4762073abd70.122.16 (deflated 6%)\n",
            "  adding: runs/Oct29_15-14-18_4762073abd70-Run(lr=0.01, batch_size=1000, num_workers=16)/ (stored 0%)\n",
            "  adding: runs/Oct29_15-14-18_4762073abd70-Run(lr=0.01, batch_size=1000, num_workers=16)/events.out.tfevents.1572362058.4762073abd70.122.11 (deflated 20%)\n",
            "  adding: runs/Oct29_15-14-56_4762073abd70-Run(lr=0.01, batch_size=10000, num_workers=2)/ (stored 0%)\n",
            "  adding: runs/Oct29_15-14-56_4762073abd70-Run(lr=0.01, batch_size=10000, num_workers=2)/events.out.tfevents.1572362096.4762073abd70.122.14 (deflated 6%)\n",
            "  adding: runs/Oct29_15-13-36_4762073abd70-Run(lr=0.01, batch_size=1000, num_workers=0)/ (stored 0%)\n",
            "  adding: runs/Oct29_15-13-36_4762073abd70-Run(lr=0.01, batch_size=1000, num_workers=0)/events.out.tfevents.1572362016.4762073abd70.122.6 (deflated 20%)\n",
            "  adding: runs/Oct29_15-13-54_4762073abd70-Run(lr=0.01, batch_size=1000, num_workers=2)/ (stored 0%)\n",
            "  adding: runs/Oct29_15-13-54_4762073abd70-Run(lr=0.01, batch_size=1000, num_workers=2)/events.out.tfevents.1572362034.4762073abd70.122.8 (deflated 20%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmiyO6uqG4ov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}